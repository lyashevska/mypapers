\documentclass[11pt, oneside, a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage[british]{babel}
\usepackage{enumitem}
\usepackage{graphics, graphicx, grffile, amsmath, amsthm, amssymb, color, colortbl}
\usepackage{natbib}
\usepackage{lineno}
\usepackage[unicode=true,pdfusetitle, bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2, breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false] {hyperref}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\usepackage{breakurl}
\renewcommand{\topfraction}{.85}
\renewcommand{\bottomfraction}{.7}
\renewcommand{\textfraction}{.15}
\renewcommand{\floatpagefraction}{.66}
\usepackage{listings}
%\usepackage{subfig}
\usepackage{caption, subcaption}

<<setup, echo=FALSE, cache=FALSE, include=FALSE>>=
library(knitr)
options(width=60)
knit_hooks$set(crop=hook_pdfcrop)
opts_knit$set(progress=TRUE, verbose=TRUE)
opts_chunk$set(cache=TRUE, message=FALSE, tidy=TRUE, cache.path='cache/', cache.lazy=FALSE, cache.comments=FALSE, fig.path='figure/', fig.keep = "all", dev="png", dev.args=list(type="cairo"), dpi=96, fig.show='hold',fig.aligh='center', crop=TRUE)
@

\title{R script for mapping zero-inflated autocorrelated species abundance data}
\author{Olga Lyashevska}
\date{\today}

\begin{document}
\maketitle

\tableofcontents
\listoftables
\listoffigures

\section{Session info}

<<library, echo=F, messages=F, cache=F>>=
#libraries
library(gstat)
library(geoR)
library(raster)
library(rgdal)
library(sp)
library(geoRglm)
library(ggplot2)
library(gstat)
library(pscl)
library(MASS)
library(corrplot)
library(stargazer)
library(coda)
library(reshape2)
@

<<include=TRUE, cache=FALSE>>=
rm(list=ls())
sessionInfo()
set.seed(5021)
@

\section{Custom functions}

\subsection{Function to classify zeros either as a Bernoulli or a Poisson}

<<myfun.sep.large>>=
myfun.sep.large<-function(sam){
samB<-sam
samB$macoma<-ifelse(samB$macoma>0,1,0)
samP<-sam
glmB <- glm(
    formula = macoma~mgs+mgs2+silt+silt2+depth+depth2+oost+noord,
    family = "binomial", 
    data = subset(samB, select=-c(x,y))
)
glmZ <- zeroinfl(
    formula =macoma~mgs+mgs2+silt+silt2+depth+depth2+oost+noord,
    link = "logit",
    dist="poisson",
    data = samP
)
p.glmB <- predict(glmB, type='response') 
summary(p.glmB)
lp.glmZ <- predict(glmZ, type='zero') 
#prob of 1
p.glmZ<-1-lp.glmZ 
summary(p.glmZ)
mu.glmZ <- predict(glmZ,type='count') 
p.glmZ.tot <- p.glmZ*exp(-mu.glmZ)
p.rat <- (1-p.glmZ)/(1-p.glmZ+p.glmZ.tot)
p.test <- runif(length(samP$macoma))
echte <- p.rat > p.test
keep<-ifelse(echte==TRUE & sam$macoma==0, FALSE, TRUE)
samP0<-samP[keep,]
samB0<-samB
samB0$macoma<-ifelse(keep==TRUE, 1, samB$macoma)
return(list(bin=samB0,pois=samP0))
}
@

<<myfun.sep.small>>=
myfun.sep.small<-function(sam){
samB<-sam
samB$macoma<-ifelse(samB$macoma>0,1,0)
samP<-sam
glmB <- glm(
    formula = macoma~silt+silt2+depth,
    family = "binomial", 
    data = subset(samB, select=-c(x,y))
)
glmZ <- zeroinfl(
    formula =macoma~silt+silt2+depth,
    link = "logit",
    dist="poisson",
    data = samP
)
p.glmB <- predict(glmB, type='response') 
summary(p.glmB)
lp.glmZ <- predict(glmZ, type='zero') 
summary(lp.glmZ)
p.glmZ<-1-lp.glmZ 
summary(p.glmZ)
mu.glmZ <- predict(glmZ,type='count') 
p.glmZ.tot <- p.glmZ*exp(-mu.glmZ)
p.rat <- (1-p.glmZ)/(1-p.glmZ+p.glmZ.tot)
p.test <- runif(length(samP$macoma))
echte <- p.rat > p.test
keep<-ifelse(echte==TRUE & sam$macoma==0, FALSE, TRUE)
samP0<-samP[keep,]
samB0<-samB
samB0$macoma<-ifelse(keep==TRUE, 1, samB$macoma)
return(list(bin=samB0,pois=samP0))
}

@

\subsection{Functions to back-transform predictions and simulations}

<<backtransforming>>=
#back transforming predictions when nsim=0, method of Christensen
#https://github.com/cran/geoRglm/blob/master/R/binom.pred.R
#https://github.com/cran/geoRglm/blob/master/R/extensions.R
#for binomial 
transf.predB<-function(var1.pred, var1.var){plogis(var1.pred) + 0.5*(exp(var1.pred)*(-expm1(var1.pred))/(1+exp(var1.pred))^3)*var1.var}
transf.varB<-function(var1.pred, var1.var){
    (exp(var1.pred)/(1+exp(var1.pred))^2)^2*var1.var+(1/2)*(exp(var1.pred)*(-expm1(var1.pred))/(1+exp(var1.pred))^3)^2*var1.var^2}
#for poisson 
transf.predP<-function(var1.pred, var1.var){exp(var1.pred+0.5*var1.var)}
transf.varP<-function(var1.pred, var1.var){(exp(2*var1.pred+var1.var))*expm1(var1.var)}
#back-transforming simulations when nsim=1 or when using output from glsm.mcmc
#for binomial
antilogit<-function(x){exp(x)/(1+exp(x))} 
#for poisson use `exp'
@

\subsection{Function to perform scaling of variables}

<<myscale>>=
myscale<-function(x){(x-mean(x))/sd(x)}
@

\subsection{Function to generate counts from prevalence and intensity}

<<myfun.count>>=
myfun.count<-function(pred.pi,pred.mu){
pred.pi<-data.frame(pred.pi)
pred.mu<-data.frame(pred.mu)
datb<-numeric()
for (i in 1:ncol(pred.pi)){
#generate random samples from bin dist
b<-rbinom(n=nrow(pred.pi), size=1, p=pred.pi[,i])
datb<-cbind(datb, b)}
datp<-numeric()
for (j in 1:ncol(pred.mu)){
#generate random samples from pois dist
d<-rpois(n=nrow(pred.mu), lambda=pred.mu[,j])
datp<-cbind(datp, d)}
res<-ifelse(datb==0,0,datp)
res<-data.frame(res)
names(res)<- c(paste(rep("X",ncol(pred.pi)),c(1:ncol(pred.pi)),sep=""))
res<-res[complete.cases(res),]
}
@

\subsection{Function to sample data}
<<myfun.sample>>=
myfun.sample <- function(x, ...){
        if(all(is.na(x))){
	            return(NA)
    }
    return(sample(x[!is.na(x)], ...))
}
@

\section{Data import and screening}

<<data, results='asis'>>=
##----dat.sep
dat<-read.csv("input/dat.csv", header=T)
#remove 4 values in macoma >100
dat<-subset(dat, macoma<100)
dat$mgs2<-dat$mgs^2
dat$silt2<-dat$silt^2
dat$depth2<-dat$depth^2
dat<-subset(dat, select=-grid)
dat<-subset(dat, select=-X)
meancov<-apply(dat, 2, mean)
sdcov<-apply(dat, 2, sd)
stargazer(subset(dat, select=-c(x, y)), summary=TRUE, rownames=FALSE, title='Original data, 4026 observations', nobs=FALSE)
dat<-cbind(dat[,c("macoma", "x", "y")],
	    apply(dat[,c( "mgs", "mgs2", "silt", 
			  "silt2", "depth","depth2", 
			  "oost", "noord")], 2, myscale))
stargazer(subset(dat, select=-c(x, y)), summary=TRUE, rownames=FALSE, title='Data after scaling, 4026 observations', nobs=FALSE)
#datsc<-dat
#write.csv(datsc, "input/datsc.csv")
@

<<hist,fig.cap='Histogram of counts of Macoma balthica.', out.width='0.8\\linewidth'>>=
df<-read.csv("./input/dat.csv")
df<-subset(df, macoma<100)
print(ggplot(df, aes(macoma))+
geom_histogram(binwidth = 2, position = "dodge") + 
scale_x_continuous(name="Species abundance")+
scale_y_continuous(name="Counts"))
#to find skewness
#library(agricolae)
#skewness(df$macoma)
@

<<corr, out.width="0.7\\linewidth", fig.cap="A graphical display of the correlation matrix of environmental variables considered for inclusion in model">>=
corrplot(cor(dat), method="ellipse", type="lower")
@

<<abundance, fig.cap='Empirical species abundance map of Macoma balthica. At many locations (yellow dots) the counts equal zero, thus assuming Gaussian distribution is inappropriate.', out.width='\\textwidth', tidy=F>>=
intertidal.shp<-readOGR("./input/intertidal", "intertidal")
RD<-CRS("+proj=sterea +lat_0=52.15616055555555 +lon_0=5.38763888888889 
	+k=0.9999079 +x_0=155000 +y_0=463000 +ellps=bessel 
	+towgs84=565.2369,50.0087,465.658,-0.406857330322398,
	0.350732676542563,-1.8703473836068,4.0812 +units=m +no_defs")
intertidal.shp<-spTransform(intertidal.shp, RD)
gg.intertidal<-ggplot(intertidal.shp) + 
geom_polygon(aes(x = long/1000, y = lat/1000, group=group), alpha=0.3)+
scale_y_continuous(name = "Northing (km)") + 
scale_x_continuous(name = "Easting (km)") + 
coord_equal()
b<-c(-Inf,1,2, Inf)
l<-c("[0-1)","[1-2)", "[2-84)")
colo<-c( "#FFFF00", "#7FC400", "#008B00")
#breaks for data
df$group<-cut(df$macoma,breaks=b, labels=l)
print(gg.intertidal+ 
      geom_point(data = df, aes( x = x* 1.0e-3, y = y* 1.0e-3, colour=group),size=0.5)+ 
      scale_colour_manual(name = "", values = colo)+ 
      theme(legend.position="bottom")+ 
      guides(colour = guide_legend(override.aes = list(size=3))))
@


\section{Model selection and zero classification}

\subsection{Bernoulli}
<<glmB>>=
#binomial model
datB<-dat
datB$macoma<-ifelse(datB$macoma>0,1,0)
glmB <- glm(formula = macoma~mgs+mgs2+silt+silt2+depth+depth2+oost+noord, family = binomial, data = datB)
dropterm(step(glmB), test="Chisq")
@

<<glmBplots, out.width='.49\\linewidth', fig.cap="Regression diagnostics plots, Bernoulli model", fig.subcap=c("Predicted versus fitted values", "QQ plot", "Predicted vs standardized residuals", "Histogram of residuals")>>=
ggplot(glmB, aes(.hat, .fitted)) +
geom_point() + geom_smooth(se = TRUE)
qplot(sample =.stdresid, data = glmB, stat = "qq") + geom_abline()
qplot(.hat, .stdresid, data = glmB, size = .cooksd) +
geom_smooth(se = FALSE, size = 0.5)
ggplot(glmB, aes(x=.resid)) + geom_histogram()
@

\subsection{Poisson}
<<glmP>>=
datP<-dat
glmP <- glm(formula = macoma~mgs+mgs2+silt+silt2+depth+depth2+oost+noord, family = poisson(link=log), data = datP)
dropterm(step(glmP), test="Chisq")
@

<<glmPplots, out.width='.49\\linewidth', fig.cap="Regression diagnostics plots, Poisson model", fig.subcap=c("Predicted versus fitted values", "QQ plot", "Predicted vs standardized residuals", "Histogram of residuals")>>=
ggplot(glmP, aes(.hat, .fitted)) +
geom_point() + geom_smooth(se = TRUE)
qplot(sample =.stdresid, data = glmP, stat = "qq") + geom_abline()
qplot(.hat, .stdresid, data = glmP, size = .cooksd) +
geom_smooth(se = FALSE, size = 0.5)
ggplot(glmP, aes(x=.resid)) + geom_histogram()
@


<<glm-summary, results='asis', tidy=F>>=
stargazer(glmB, glmP, no.space=TRUE, single.row=TRUE, 
	  title='Generalised linear models for Bernoulli and Poisson datasets', 
	  object.names=FALSE, model.numbers = FALSE)
@

\subsection{Zero classification}

<<dat.sep>>=
trendP<-glmP$formula
trendB<-glmB$formula
dat.sep<-myfun.sep.large(dat)
table(dat.sep$bin$macoma==0)
table(dat.sep$pois$macoma==0)
@

\section{Estimation of variogram parameters}
\subsection{Method of moments}

\subsubsection{Bernoulli}
<<modelvar>>=
bin<-dat.sep$bin
bin.glm<-glm(formula=trendB, family = "binomial", data = bin)
bin$residB <- resid(bin.glm, type='response')
bin.glm.beta<-as.numeric(bin.glm$coefficients)
coordinates(bin)<-c("x","y")
samplevarB <- variogram(residB ~ 1, data = bin, cutoff=3000)
modelvarB <- vgm(psill = 0.03, model = "Sph", range = 2500, nugget = 0.2)
modelvarB <- fit.variogram(samplevarB, model = modelvarB)
linevarB<-variogramLine(modelvarB,maxdist=max(samplevarB$dist))
@

\subsubsection{Poisson}
<<modelvarP>>=
pois<-dat.sep$pois
pois.glm<-glm(formula=trendP, family = "poisson", data = pois)
pois$residP <- resid(pois.glm,type='deviance')
pois.glm.beta<-as.numeric(pois.glm$coefficients)
coordinates(pois)<-c("x","y")
samplevarP <- variogram(residP ~ 1, data = pois, cutoff=3000)
modelvarP <- vgm(psill = 2, model = "Sph", range = 2500, nugget = 3)
modelvarP <- fit.variogram(samplevarP, model = modelvarP)
linevarP<-variogramLine(modelvarP,maxdist=max(samplevarP$dist))
@

<<samplevarplot, out.width="0.49\\linewidth", fig.cap="Empirical and fitted theoretical variograms, semivariances are given by the number of point pairs multiplied by 0.01", fig.subcap= c("Bernoulli model", "Poisson model", tidy=TRUE)>>=
ggplot(data = as.data.frame(samplevarB))+ 
geom_line(data=linevarB,aes(x=dist,y=gamma))+
geom_text(mapping = aes(x = dist, y = gamma, 
label = round(np / 100)), size=4) + 
scale_x_continuous(name = expression((h)*"  (m)")) +
scale_y_continuous(name = expression((gamma)*"  (-)"), 
limits = c(0, max(samplevarB$gamma))) + 
theme(legend.position="none")
ggplot(data = as.data.frame(samplevarP))+
geom_line(data=linevarP,aes(x=dist,y=gamma))+
geom_text(mapping = aes(x = dist, y = gamma, 
			label = round(np / 100)), size=4) +
scale_x_continuous(name = expression((h)*"  (m)")) +
scale_y_continuous(name = expression((gamma)*"  (-)"), 
limits = c(0, max(samplevarP$gamma))) + 
theme(legend.position="none")
@

\subsection{Restricted maximum likelihood}

\subsubsection{Bernoulli}

<<bin.reml, eval=F>>=
bin.geo<-as.geodata(
    obj = as.data.frame(bin),
    header = TRUE,
    coords.col = c("x","y"),
    data.col = "residB", 
    data.names = NULL,
    covar.col = c("mgs","mgs2", "silt","silt2","depth","depth2", "oost", "noord")
)
bin.reml <- likfit(
    geodata = bin.geo,
    trend="cte", 
    cov.model="spherical", 
    ini.cov.pars=c(modelvarB[2,2], modelvarB[2,3]), 
    nugget=modelvarB[1,2],
    lik.method="REML"
)
saveRDS(bin.reml,"output/bin.reml.rds")
@

<<text='asis'>>=
bin.reml<-readRDS("output/bin.reml.rds")
bin.reml
@

\subsubsection{Poisson}

<<pois.reml, eval=F>>=
pois.geo<-as.geodata(
    obj = as.data.frame(pois),
    header = TRUE,
    coords.col = c("x","y"),
    data.col = "residP", 
    data.names = NULL,
    covar.col = c("mgs","mgs2", "silt","silt2","depth","depth2", "oost", "noord")
)
pois.reml <- likfit(
    geodata = pois.geo,
    trend="cte", 
    cov.model="spherical", 
    ini.cov.pars=c(modelvarP[2,2], modelvarP[2,3]), 
    nugget=modelvarP[1,2],
    lik.method="REML"
)
saveRDS(pois.reml,"output/pois.reml.rds")
@

<<text='asis'>>=
pois.reml<-readRDS("output/pois.reml.rds")
pois.reml
@

\section{Markov chain Monte Carlo}
\subsection{Bernoulli}

<<bin.simFtilde, eval=F, tidy=F>>=
bin.mcmc.geo<-as.geodata(
    obj = as.data.frame(bin),
    header = TRUE,
    coords.col = c("x","y"),
    data.col = "macoma", 
    data.names = NULL,
    covar.col = c("mgs","mgs2", "silt","silt2","depth","depth2", "oost", "noord")
)
mcmcSetB <- mcmc.control(S.scale = 0.15, thin = 50, burn.in = 100)
glgmB <- list(
    family='binomial', 
    trend=trend.spatial(trend=trendB, geodata=as.data.frame(bin)),
    cov.model='spherical', 
    cov.pars=c(bin.reml$sigmasq, bin.reml$phi), 
    nugget =bin.reml$tausq,
    beta=bin.glm.beta)
bin.simFtilde <- glsm.mcmc(
    geodata = bin.mcmc.geo, 
    model = glgmB, 
    mcmc.input = mcmcSetB,
    messages=TRUE)
saveRDS(bin.simFtilde,"output/bin.simFtilde.rds")
@

<<read.bin.simFtilde, out.width="0.49\\linewidth", fig.cap="MCMC convergence diagnostics, Bernoulli model.", fig.subcap= c("Trace plot of iterations versus sampled values after the burn-in period", "The autocorrelation function in each chain", "The density plot", "Geweke-Brooks plot")>>=
mcmcSetB <- mcmc.control(S.scale = 0.15, thin = 50, burn.in = 100)
bin.simFtilde<-readRDS("output/bin.simFtilde.rds")
bin.chainConv1 <- create.mcmc.coda(x = bin.simFtilde$simulations[round(runif(1, min = 1, max = nrow(bin.simFtilde$simulations)),0),], mcmc.input = mcmcSetB)  
traceplot(bin.chainConv1)
autocorr.plot(bin.chainConv1, auto.layout=FALSE)
densplot(bin.chainConv1)
geweke.plot(bin.chainConv1, auto.layout=FALSE)
@

\subsection{Poisson}

<<pois.simFtilde, eval=F, tidy=F>>=
pois.mcmc.geo<-as.geodata(
    obj = as.data.frame(pois),
    header = TRUE,
    coords.col = c("x","y"),
    data.col = "macoma", 
    data.names = NULL,
    covar.col = c("mgs","mgs2", "silt","silt2","depth","depth2", "oost", "noord")
)
mcmcSetP <- mcmc.control(S.scale = 0.1, thin = 50, burn.in = 100)
glgmP <- list(
    family='poisson', 
    trend =trend.spatial(trendP, as.data.frame(pois)),
    cov.model='spherical', 
    cov.pars=c(pois.reml$sigmasq, pois.reml$phi), 
    nugget =pois.reml$tausq,
    beta=pois.glm.beta)
pois.simFtilde <- glsm.mcmc(
    geodata = pois.mcmc.geo, 
    model = glgmP, 
    mcmc.input = mcmcSetP,
    messages=TRUE)
saveRDS(pois.simFtilde,"output/pois.simFtilde.rds")
@

<<read.pois.simFtilde, out.width="0.49\\linewidth", fig.cap="MCMC convergence diagnostics, Poisson model.", fig.subcap= c("Trace plot of iterations versus sampled values after the burn-in period", "The autocorrelation function in each chain", "The density plot", "Geweke-Brooks plot")>>=
mcmcSetP <- mcmc.control(S.scale = 0.1, thin = 50, burn.in = 100)
pois.simFtilde<-readRDS("output/pois.simFtilde.rds")
pois.chainConv1 <- create.mcmc.coda(x = pois.simFtilde$simulations[round(runif(1, min = 1, max = nrow(pois.simFtilde$simulations)),0),], mcmc.input = mcmcSetP) # 
traceplot(pois.chainConv1)
autocorr.plot(pois.chainConv1, auto.layout=FALSE)
densplot(pois.chainConv1)
geweke.plot(pois.chainConv1, auto.layout=FALSE)
@

\section{Markov chain maximum likelihood}
\subsection{Bernoulli}
<<bin.mcml1, eval=F>>=
bin.mcmlPrep1 <- prepare.likfit.glsm(bin.simFtilde)  
bin.mcml1 <- likfit.glsm(
    mcmc.obj = bin.mcmlPrep1, 
    cov.model = "spherical", 
    ini.phi = bin.reml$phi, 
    nugget.rel = (bin.reml$tausq/bin.reml$sigmasq), 
    fix.nugget.rel = FALSE,
    messages = FALSE
)
saveRDS(bin.mcml1, "output/bin.mcml1.rds")
bin.simF <- glsm.mcmc(
    geodata =bin.mcmc.geo, 
    units.m = "default", 
    model = bin.mcml1,  
    mcmc.input = mcmcSetB, 
    messages=FALSE
)
saveRDS(bin.simF, "output/bin.simF.rds")
@

<<read.bin.simF, out.width="0.49\\linewidth", fig.cap="MCMC convergence diagnostics, Bernoulli model (second run).", fig.subcap= c("Trace plot of iterations versus sampled values after the burn-in period", "The autocorrelation function in each chain", "The density plot", "Geweke-Brooks plot")>>=
bin.simF<-readRDS("output/bin.simF.rds")
bin.chainConv2 <- create.mcmc.coda(x = bin.simF$simulations[round(runif(1, min = 1, max = nrow(bin.simF$simulations)),0),], mcmc.input = mcmcSetB)  
traceplot(bin.chainConv2)
autocorr.plot(bin.chainConv2, auto.layout=FALSE)
densplot(bin.chainConv2)
geweke.plot(bin.chainConv2, auto.layout=FALSE)
@

<<text='asis'>>=
bin.mcml1<-readRDS("output/bin.mcml1.rds")
bin.mcml1
@

<< bin.mcml2, eval=F>>=
bin.mcmlPrep2 <- prepare.likfit.glsm(bin.simF)   
bin.mcml2 <- likfit.glsm(
  mcmc.obj = bin.mcmlPrep2, 
  cov.model = "spherical", 
  ini.phi = bin.mcml1$cov.pars[2], 
  nugget.rel = bin.mcml1$nugget.rel, 
  fix.nugget.rel = FALSE,
  messages = TRUE
)
saveRDS(bin.mcml2,"output/bin.mcml2.rds")
bin.simF2 <- glsm.mcmc(
  geodata = bin.mcmc.geo, 
  units.m = "default", 
  model = bin.mcml2, 
  mcmc.input = mcmcSetB, 
  messages=TRUE
)
saveRDS(bin.simF2,"output/bin.simF2.rds")
@

<<text='asis'>>=
bin.mcml2<-readRDS("output/bin.mcml2.rds")
bin.mcml2
@

\subsection{Poisson}
<< pois.mcml1, eval=F>>=
pois.mcmlPrep1 <- prepare.likfit.glsm(pois.simFtilde)  
pois.mcml1 <- likfit.glsm(
    mcmc.obj = pois.mcmlPrep1, 
    cov.model = "spherical", 
    ini.phi = pois.reml$phi, 
    nugget.rel = (pois.reml$tausq/pois.reml$sigmasq), 
    fix.nugget.rel = FALSE,
    messages = FALSE
)
saveRDS(pois.mcml1, "output/pois.mcml1.rds")
pois.simF <- glsm.mcmc(
    geodata =pois.mcmc.geo, 
    units.m = "default", 
    model = pois.mcml1,  
    mcmc.input = mcmcSetP, 
    messages=FALSE
)
saveRDS(pois.simF, "output/pois.simF.rds")
@

<<read.pois.simF, out.width="0.49\\linewidth", fig.cap="MCMC convergence diagnostics, Poisson model (second run).", fig.subcap= c("Trace plot of iterations versus sampled values after the burn-in period", "The autocorrelation function in each chain", "The density plot", "Geweke-Brooks plot")>>=
pois.simF<-readRDS("output/pois.simF.rds")
pois.chainConv2 <- create.mcmc.coda(x = pois.simF$simulations[round(runif(1, min = 1, max = nrow(pois.simF$simulations)),0),], mcmc.input = mcmcSetP) # 
traceplot(pois.chainConv2)
autocorr.plot(pois.chainConv2, auto.layout=FALSE)
densplot(pois.chainConv2)
geweke.plot(pois.chainConv2, auto.layout=FALSE)
@

<<text='asis'>>=
pois.mcml1<-readRDS("output/pois.mcml1.rds")
pois.mcml1
@

<<pois.mcml2, eval=F>>=
pois.mcmlPrep2 <- prepare.likfit.glsm(pois.simF)   
pois.mcml2 <- likfit.glsm(
  mcmc.obj = pois.mcmlPrep2, 
  cov.model = "spherical", 
  ini.phi = pois.mcml1$cov.pars[2], 
  nugget.rel = pois.mcml1$nugget.rel, 
  fix.nugget.rel = FALSE,
  messages = TRUE
)
saveRDS(pois.mcml2,"output/pois.mcml2.rds")
pois.simF2 <- glsm.mcmc(
  geodata = pois.mcmc.geo, 
  units.m = "default", 
  model = pois.mcml2, 
  mcmc.input = mcmc.control(S.scale = 0.2, thin = 100, burn.in = 100),
  messages=TRUE
)
saveRDS(pois.simF2,"output/pois.simF2.rds")
@

<<text='asis'>>=
pois.mcml2<-readRDS("output/pois.mcml2.rds")
pois.mcml2
@

<<pois.mcml3, eval=F>>=
pois.mcmlPrep3 <- prepare.likfit.glsm(pois.simF2)   
pois.mcml3 <- likfit.glsm(
  mcmc.obj = pois.mcmlPrep3, 
  cov.model = "spherical", 
  ini.phi = pois.mcml2$cov.pars[2], 
  nugget.rel = pois.mcml2$nugget.rel, 
  fix.nugget.rel = FALSE,
  messages = TRUE
)
saveRDS(pois.mcml3,"output/pois.mcml3.rds")
pois.simF3 <- glsm.mcmc(
  geodata = pois.mcmc.geo, 
  units.m = "default", 
  model = pois.mcml3, 
  mcmc.input = mcmc.control(S.scale = 0.2, thin = 100, burn.in = 100),
  messages=TRUE
)
saveRDS(pois.simF3,"output/pois.simF3.rds")
#rename simulated mcmc and mcml
simF2B<-bin.simF2
mcmlEstimation2B<-bin.mcml2
simF2P<-pois.simF3
mcmlEstimation2P<-pois.mcml3
@

<<text='asis'>>=
pois.mcml3<-readRDS("output/pois.mcml3.rds")
pois.mcml3
@

\section{Prediction}
\subsection{Prediction grid}
<<sgrid, eval=F>>=
sgrid <- spsample(
      intertidal.shp,
      cellsize =100,
      type = "regular",
      offset = c(0.5, 0.5)) 
proj4string(sgrid) <-RD
depth<-raster("input/depth2.grd")
mindepth<- -200
maxdepth<- 100
grddepth <- over(sgrid, as(depth,"SpatialGridDataFrame"))
ids<-which(grddepth$layer> mindepth & grddepth$layer < maxdepth )
sgrid<-sgrid[ids,]
grddepth<-grddepth[ids,]
tmp<-dat
coordinates(tmp)<-~x+y
proj4string(tmp)<-RD
silt.idw<-idw(silt~1, tmp, sgrid)
silt2.idw<-idw(silt2~1, tmp, sgrid)
mgs.idw<-idw(mgs~1, tmp, sgrid)
mgs2.idw<-idw(mgs2~1, tmp, sgrid)
sgrid<-as.data.frame(sgrid)
sgrid$mgs<-mgs.idw$var1.pred
sgrid$mgs2<-mgs2.idw$var1.pred
sgrid$silt<-silt.idw$var1.pred
sgrid$silt2<-silt2.idw$var1.pred
sgrid$depth<-(grddepth-meancov["depth"])/sdcov["depth"]
sgrid$depth2<-(grddepth^2-meancov["depth2"])/sdcov["depth2"]
sgrid$oost<-(sgrid$x/100-meancov["oost"])/sdcov["oost"]
sgrid$noord<-(sgrid$y/100-meancov["noord"])/sdcov["noord"]
sgrid<-sgrid[complete.cases(sgrid),]
coordinates(sgrid)<-c("x","y")
proj4string(sgrid) <- RD
@

\subsection{Prediction models}

<<vgm, eval=F>>=
vgmB <- vgm(model="Sph",
psill = mcmlEstimation2B$cov.pars[1],
range= mcmlEstimation2B$cov.pars[2],
nugget= mcmlEstimation2B$nugget.rel*mcmlEstimation2B$cov.pars[1])

vgmP <- vgm(model="Sph",
psill = mcmlEstimation2P$cov.pars[1],
range= mcmlEstimation2P$cov.pars[2],
nugget= mcmlEstimation2P$nugget.rel*mcmlEstimation2P$cov.pars[1])
@

\subsection{Bernoulli}
<<predB, eval=F, tidy=F>>=
nsm<-100
predB<-varB<-NULL
for (i in 1:nsm){
S.sibesB<-as.data.frame(cbind(
			      simF2B$geodata$coords,
			      simF2B$simulations[,i], 
			      simF2B$geodata$covariate))
names(S.sibesB)<-c("x","y","S", names(simF2B$geodata$covariate))
coordinates(S.sibesB)<-~x+y
proj4string(S.sibesB)<-RD
S.krige.predB <- krige(
    formula = S~mgs+mgs2+silt+silt2+depth+depth2+oost+noord,
    locations = S.sibesB,
    newdata=sgrid,
    model = vgmB,
    beta = mcmlEstimation2B$beta,
    nmax=100,
    nsim=0, #use kriging interpolation
    debug.level=1
)
#prediction
predB<-cbind(predB,S.krige.predB$var1.pred)
#kriging var
varB<-cbind(varB,S.krige.predB$var1.var)
}
colnames(predB)<-paste(rep("S",ncol(predB)),c(1:ncol(predB)),sep="")
colnames(varB)<-paste(rep("S",ncol(varB)),c(1:ncol(varB)),sep="")
predB<-data.frame(sgrid@coords, predB)
varB<-data.frame(sgrid@coords, varB)
saveRDS(object=predB,file="./output/predB.rds")
saveRDS(object=varB,file="./output/varB.rds")
@

\subsection{Poisson}
<<predP, eval=F, tidy=F>>=
nsm<-100
predP<-varP<-NULL
for (i in 1:nsm){
S.sibesP<-as.data.frame(cbind(
			      simF2P$geodata$coords,
			      simF2P$simulations[,i], 
			      simF2P$geodata$covariate))
names(S.sibesP)<-c("x","y","S", names(simF2P$geodata$covariate))
coordinates(S.sibesP)<-~x+y
proj4string(S.sibesP)<-RD
S.krige.predP <- krige(
    formula = S~mgs+mgs2+silt+silt2+depth+depth2+oost+noord,
locations = S.sibesP,
newdata=sgrid,
model = vgmP,
beta = mcmlEstimation2P$beta,
nmax=100,
nsim=0,
debug.level=1
)
predP<-cbind(predP,S.krige.predP$var1.pred)
varP<-cbind(varP,S.krige.predP$var1.var)
}
colnames(predP)<-paste(rep("S",ncol(predP)),c(1:ncol(predP)),sep="")
colnames(varP)<-paste(rep("S",ncol(varP)),c(1:ncol(varP)),sep="")
predP<- data.frame(sgrid@coords, predP)
varP<-data.frame(sgrid@coords, varP)
saveRDS(object=predP,file="./output/predP.rds")
saveRDS(object=varP,file="./output/varP.rds")
@

\subsection{Transformation of kriging prediction and kriging variance}
<<pred.mean, eval=F>>=
##----pi.pred.mean pi.var.mean
pi.pred<-mapply(transf.predB, var1.pred=predB[,-c(1:2)], var1.var=varB[,-c(1:2)])
#dim(pi.pred)
#115145 100
pi.var<-mapply(transf.varB, var1.pred=predB[,-c(1:2)], var1.var=varB[,-c(1:2)])
#take average over 100 S
pi.pred.mean<-data.frame(predB[,c(1:2)], pi.pred.mean=rowMeans(pi.pred))
#predicted variance is obtained by taking the mean of the predicted variance plus the variance of the predicted means
pi.var.mean<-data.frame(varB[,c(1:2)],pi.var.mean= rowMeans(pi.var)+apply(pi.pred, 1, var))
saveRDS(pi.pred.mean, file="./output/pi.pred.mean.rds")
saveRDS(pi.var.mean, file="./output/pi.var.mean.rds")
##----mu.pred.mean mu.var.mean
mu.pred<-mapply(transf.predP, var1.pred=predP[,-c(1:2)], var1.var=varP[,-c(1:2)])
#dim(mu.pred)
#115145 100
mu.var<-mapply(transf.varP, var1.pred=predP[,-c(1:2)], var1.var=varP[,-c(1:2)])
#take average over 100 S
mu.pred.mean<-data.frame(predP[,c(1:2)], mu.pred.mean=rowMeans(mu.pred))
mu.var.mean<-data.frame(varP[,c(1:2)],mu.var.mean= rowMeans(mu.var)+apply(mu.pred, 1, var))
saveRDS(mu.pred.mean, file="./output/mu.pred.mean.rds")
saveRDS(mu.var.mean, file="./output/mu.var.mean.rds")
##----pimu.pred pimu.var
pimu.pred<-pi.pred*mu.pred
pimu.pred<-rowMeans(pimu.pred)
pimu.pred<-data.frame(predP[,c(1:2)],pimu.pred) 
varpi<-apply(pi.pred,1,var)
varmu<-apply(mu.pred,1,var)
Epi2<-apply(pi.pred,1,function(x){mean(x)^2})
Emu2<-apply(mu.pred,1,function(x){mean(x)^2})
pimu.var<-varpi*varmu+varpi*Emu2+varmu*Epi2
#coefficient of variation sqrt(var)/mean=sd/mean
pimu.cv<-sqrt(pimu.var)/pimu.pred[,3]
pimu.cv<-data.frame(predP[,c(1:2)],pimu.cv) 
saveRDS(pimu.pred, file="./output/pimu.pred.rds")
saveRDS(pimu.cv, file="./output/pimu.cv.rds")
@

\subsection{Prediction maps}
<<read.pred.mean>>=
pi.pred.mean<-readRDS("./output/pi.pred.mean.rds")
pi.var.mean<-readRDS("./output/pi.var.mean.rds")
mu.pred.mean<-readRDS("./output/mu.pred.mean.rds")
mu.var.mean<-readRDS("./output/mu.var.mean.rds")
pimu.pred<-readRDS("./output/pimu.pred.rds")
pimu.cv<-readRDS("./output/pimu.cv.rds")
@

<<fig.pi.pred.mean, out.width="0.9\\linewidth", fig.cap=" Predicted prevalence (a) and standard deviation of predicted prevalence divided by mean of predicted prevalence (b). Average of 100 realisations.", tidy=F>>=
##----pi.pred.mean
df<-pi.pred.mean
mean.pi.pred.mean<-(df[,3])
quantile(df$pi.pred.mean)
b<-c(-Inf,0.2,0.5,0.8,Inf)
l<-c("[0-0.2)", "[0.2-0.5)","[0.5-0.8)", "[0.8-1)")
colo<-c("#FFFF00", "#AAD800", "#55B100", "#008B00")
df$group<-cut(pi.pred.mean[,3],breaks=b, labels=l, right=F) #[)
table(df$group)
gg.pi.pred<-ggplot(
data = df, 
aes( x = x* 1.0e-3, y = y* 1.0e-3, color=group))+
geom_point(size=0.2)+ 
scale_color_manual(name="", values=colo)+
scale_x_continuous(name = "Easting  (km)") + 
scale_y_continuous(name = "Northing  (km)") +
coord_equal(ratio = 1)+
theme(legend.position="bottom")+
guides(colour = guide_legend(override.aes = list(size=3)))
gg.pi.pred
##----pi.var.mean
df<-pi.var.mean
df$pi.var.mean<-(sqrt(df$pi.var.mean))/mean.pi.pred.mean
quantile(df$pi.var.mean)
b<-c(-Inf,0.2,0.3,Inf)
l<-c("[0-0.01)","[0.01-0.1)", "[0.1-Inf)")
colo=c("#CDC673", "#AC744B", "#8B2323")
df$group<-cut(df$pi.var.mean,breaks=b, labels=l, right=F)
table(df$group)
gg.pi.var<-ggplot(
		  data = df, 
		  aes( x = x* 1.0e-3, y = y* 1.0e-3, color=group))+
geom_point(size=0.2)+ 
scale_color_manual(name="", values=colo)+
scale_x_continuous(name = "Easting  (km)") + 
scale_y_continuous(name = "Northing  (km)") +
coord_equal(ratio = 1)+
theme(legend.position="bottom")+
guides(colour = guide_legend(override.aes = list(size=3)))
gg.pi.var
@

<<fig.mu.pred.mean, out.width="0.9\\linewidth", fig.cap=" Predicted intensity and standard deviation of predicted intensity divided by mean of predicted intensity Average of 100 realisations.", tidy=F>>=
##----mu.pred.mean
df<-mu.pred.mean
mean.mu.pred.mean<-df[,3]
quantile(mu.pred.mean[,3])
b<-c(-Inf,1,2,5, Inf)
l<-c("[0-1)", "[1-2)","[2-5)", "[5-46)")
colo<-c("#FFFF00", "#AAD800", "#55B100", "#008B00")
df$group<-cut(mu.pred.mean[,3],breaks=b, labels=l, right=F) #[)
table(df$group)
gg.mu.pred<-ggplot(
		   data = df, 
		   aes( x = x* 1.0e-3, y = y* 1.0e-3, colour=group))+
geom_point(size=0.2)+ 
scale_colour_manual(name="", values = colo)+
scale_x_continuous(name = "Easting  (km)") + 
scale_y_continuous(name = "Northing  (km)") +
coord_equal(ratio = 1)+
theme(legend.position="bottom")+
guides(colour = guide_legend(override.aes = list(size=3)))
gg.mu.pred
df<-mu.var.mean
df$mu.var.mean<-(sqrt(df$mu.var.mean))/mean.mu.pred.mean
quantile(df$mu.var.mean)
b<-c(-Inf,1,1.1,Inf)
l<-c("[0-1)","[1-1.1)", "[1.1-Inf)")
colo<-c("#CDC673","#AC744B", "#8B2323")
df$group<-cut(df$mu.var.mean,breaks=b, labels=l, right=F)
table(df$group)
gg.mu.var<-ggplot(
		  data = df, 
		  aes( x = x* 1.0e-3, y = y* 1.0e-3, colour=group))+
geom_point(size=0.2)+ 
scale_colour_manual(name="", values = colo)+
scale_x_continuous(name = "Easting  (km)") + 
scale_y_continuous(name = "Northing  (km)") +
coord_equal(ratio = 1)+
theme(legend.position="bottom")+
guides(colour = guide_legend(override.aes = list(size=3)))
gg.mu.var
@

<<fig.pimu.pred.mean, out.width="0.9\\linewidth", fig.cap=" Predicted unconditional intensity and standard deviation of predicted unconditional intensity divided by mean of predicted unconditonal intensity. Average of 100 realisations.", tidy=F>>=
#pi*mu pred 
df<-pimu.pred
quantile(df[,3])
b<-c(-Inf,0.3,0.7,1.5, Inf)
l<-c("[0-0.3)", "[0.3-0.7)","[0.7-1.5)", "[1.5-30)")
colo<-c("#FFFF00", "#AAD800", "#55B100", "#008B00")
df$group<-cut(df[,3],breaks=b, labels=l, right=F) 
table(df$group)
gg.pimu.pred<-ggplot(data = df, 
		     aes( x = x* 1.0e-3, y = y* 1.0e-3, colour=group))+
geom_point(size=0.2)+ 
scale_colour_manual(name="", values = colo)+
scale_x_continuous(name = "Easting  (km)") + 
scale_y_continuous(name = "Northing  (km)") +
coord_equal(ratio = 1)+
theme(legend.position="bottom")+
guides(colour = guide_legend(override.aes = list(size=3)))
gg.pimu.pred
#pi*mu var
df<-pimu.cv
quantile(df[,3])
b<-c(-Inf,0.20,0.25,0.30, Inf)
l<-c("[0-0.20)", "[0.20-0.25)","[0.25-0.30)", "[0.30-0.40)")
colo<-c("#CDC673","#B78F58","#A1593D","#8B2323")
df$group<-cut(df[,3],breaks=b, labels=l, right=F) 
table(df$group)
gg.pimu.cv<-ggplot(data = df, 
		   aes( x = x* 1.0e-3, y = y* 1.0e-3, colour=group))+
geom_point(size=0.2)+ 
scale_colour_manual(name="", values = colo)+
scale_x_continuous(name = "Easting  (km)") + 
scale_y_continuous(name = "Northing  (km)") +
coord_equal(ratio = 1)+
theme(legend.position="bottom")+
guides(colour = guide_legend(override.aes = list(size=3)))
gg.pimu.cv
@

\section{Cross-validation}

\subsection{Predicted prevalence}
<< xvalB, eval=F >>=
nsm<-100
xvalB<-NULL
for (i in 1:nsm){
S.sibesB<-as.data.frame(cbind(simF2B$geodata$coords,simF2B$simulations[,i], simF2B$geodata$covariate))
names(S.sibesB)<-c("x","y","S", names(simF2B$geodata$covariate))
xvalB[[i]]<-krige.cv(
    formula = S~mgs+mgs2+silt+silt2+depth+depth2+oost+noord,
		data=S.sibesB,
		locations=~x+y,
		model=vgmB,
    		beta = mcmlEstimation2B$beta,
		nmax=100,
		nfold=nrow(S.sibesB),
		debug.level=1,
		verbose=TRUE
		)
}
#save a list of dataframes
saveRDS(object=xvalB, file="./output/xvalB.rds")
@

<<>>=
xvalB<-readRDS("./output/xvalB.rds")
nsm<-100
pi.obs<-pi.pr<-sb.obs<-sb.pr<-matrix(nrow=nrow(xvalB[[1]]),ncol=nsm)
for (i in 1:nsm){
#signal
sb.obs[,i]<-xvalB[[i]]$observed
sb.pr[,i]<-xvalB[[i]]$var1.pred
#pi and mu
pi.obs[,i]<-antilogit(xvalB[[i]]$observed)
pi.pr[,i]<-transf.predB(xvalB[[i]]$var1.pred, xvalB[[i]]$var1.var)
}
#identify bernoulli locations
bin.dat.obs<-readRDS("output/dat.bin.rds")
bin.dat.obs<-bin.dat.obs$data
bin.pr<-ifelse(rowMeans(pi.pr)>0.5,1,0)
#confusion matrix
table(bin.dat.obs, bin.pr)
#x obs pred
x00<-table(bin.dat.obs, bin.pr)[[1]]
x01<-table(bin.dat.obs, bin.pr)[[3]]
x10<-table(bin.dat.obs, bin.pr)[[2]]
x11<-table(bin.dat.obs, bin.pr)[[4]]
#correctly predicted 0
x00/(x00+x01)
#correctly predicted 1
x11/(x11+x10)
#overall purity (accuracy)
(x11+x00)/(x00+x01+x10+x11)
#map unit purity (users accuracy)
#present
x11/(x11+x01)
#absent
x00/(x00+x10)
#class representation (producer's accuracy)
#present
x11/(x10+x11)
#absent
x00/(x00+x01)
@

\subsection{Predicted intensity}
<<xvalP, eval=F>>=
nsm<-100
xvalP<-vector('list', length=nsm)
for (i in 1:nsm){
S.sibesP<-as.data.frame(cbind(simF2P$geodata$coords,simF2P$simulations[,i], simF2P$geodata$covariate))
names(S.sibesP)<-c("x","y","S", names(simF2P$geodata$covariate))
xvalP[[i]]<-krige.cv(
    formula = S~mgs+mgs2+silt+silt2+depth+depth2+oost+noord,
		data=S.sibesP,
		locations=~x+y,
		model=vgmP,
    		beta = mcmlEstimation2P$beta,
		nmax=100,
		nfold=nrow(S.sibesP),
		debug.level=1,
		verbose=TRUE
		)
}
saveRDS(object=xvalP, file="./output/xvalP.rds")
@

<<>>=
xvalP<-readRDS("./output/xvalP.rds")
mu.obs<-mu.pr<-sp.obs<-sp.pr<-matrix(nrow=nrow(xvalP[[1]]),ncol=nsm)
for (i in 1:nsm){
sp.obs[,i]<-xvalP[[i]]$observed
sp.pr[,i]<-xvalP[[i]]$var1.pred
mu.obs[,i]<-exp(xvalP[[i]]$observed)
mu.pr[,i]<-transf.predP(xvalP[[i]]$var1.pred, xvalP[[i]]$var1.var)}
pois.dat.obs<-readRDS("output/dat.pois.rds")
pois.dat.obs<-pois.dat.obs$data
var(pois.dat.obs)
me.mu<-mean(rowMeans(mu.pr)-pois.dat.obs)
me.mu
mse.mu<-mean((rowMeans(mu.pr)-pois.dat.obs)^2)
mse.mu
rpd<-sqrt(var(pois.dat.obs))/sqrt(mse.mu)
rpd
@

\subsection{Predicted unconditional intensity}
<<crossval-pimu, eval=F>>=
#Cross-validation of pi*mu (predicted unconditional expected count)
dat.obs<-read.csv("input/dat.csv", header=T)
#remove 4 values in macoma >100
dat.obs<-subset(dat.obs, macoma<100)
#variance in data, we hope that mse smaller than var(obs), meaning that model is useful, if not a simple average is enough
var(dat.obs$macoma)
#find locations of bernoulli zeros 
bin.dat.obs<-readRDS("output/dat.bin.rds")
#covert to df
bin.dat.obs<-cbind(bin.dat.obs$coords,bin.dat.obs$data, bin.dat.obs$covariate)
names(bin.dat.obs)[3]<-"macoma"
xy.sp.pr2<-subset(bin.dat.obs,(!bin.dat.obs$x %in% xvalP[[1]]$x & !bin.dat.obs$y %in% xvalP[[1]]$y), select=-3)
#read signal and model
simF2P<-readRDS("output/pois.simF3.rds")
mcmlEstimation2P<-readRDS("output/pois.mcml3.rds")
vgmP <- vgm(model="Sph",
psill = mcmlEstimation2P$cov.pars[1],
range= mcmlEstimation2P$cov.pars[2],
nugget= mcmlEstimation2P$nugget.rel*mcmlEstimation2P$cov.pars[1])
#predict poisson signal at bernoulli locations
nsm<-100
xvalP2<-vector('list', length=nsm)
for (i in 1:nsm){
S.sibesP<-as.data.frame(cbind(simF2P$geodata$coords,simF2P$simulations[,i], simF2P$geodata$covariate))
names(S.sibesP)<-c("x","y","S", names(simF2P$geodata$covariate))
xvalP2[[i]]<-krige(
    formula = S~mgs+mgs2+silt+silt2+depth+depth2+oost+noord,
		data=S.sibesP,
		locations=~x+y,
		newdata=xy.sp.pr2,
		model=vgmP,
    		beta = mcmlEstimation2P$beta,
		nmax=100,
		nsim=0,
	       	debug.level=1
		)
}
saveRDS(object=xvalP2, file="./output/xvalP2.rds")
#reshape to matrix
mu.pr2<-matrix(nrow=nrow(xvalP2[[1]]),ncol=nsm)
for (i in 1:nsm){
mu.pr2[,i]<-transf.predP(xvalP2[[i]]$var1.pred, xvalP2[[i]]$var1.var)
}
#add coordinates
xy.mu.pr2<-cbind(xvalP2[[1]]$x,xvalP2[[1]]$y,mu.pr2)
xy.mu.pr1<-cbind(xvalP[[1]]$x,xvalP[[1]]$y,mu.pr)
xy.pi.pr<-cbind(xvalB[[1]]$x,xvalB[[1]]$y,pi.pr)
#split predicted pi (xy.pi.pr) in 2 subsets 
#1633 poisson loc
xy.pi.pr1<-subset(xy.pi.pr,(xy.pi.pr[,1] %in% xy.mu.pr1[,1] & xy.pi.pr[,2] %in% xy.mu.pr1[,2]))
#2393 bernoulli 0
xy.pi.pr2<-subset(xy.pi.pr,(xy.pi.pr[,1] %in% xy.mu.pr2[,1] & xy.pi.pr[,2] %in% xy.mu.pr2[,2]))
#split observed sibes
obs1<-subset(dat.obs,(dat.obs$x %in% xvalP[[1]]$x & dat.obs$y %in% xvalP[[1]]$y), select=macoma)
obs2<-subset(dat.obs,(!dat.obs$x %in% xvalP[[1]]$x & !dat.obs$y %in% xvalP[[1]]$y), select=macoma)
#averages of 100 products
pimu.pr1<-rowMeans(xy.pi.pr1[,-c(1:2)]*xy.mu.pr1[,-c(1:2)])
pimu.pr2<-rowMeans(xy.pi.pr2[,-c(1:2)]*xy.mu.pr2[,-c(1:2)])
me.pimu<-mean(rbind((pimu.pr1-as.matrix(obs1)),(pimu.pr2-as.matrix(obs2))))
me.pimu
## -0.18
mse.pimu<-mean(rbind(((pimu.pr1-obs1)^2), ((pimu.pr2-obs2)^2)))
mse.pimu
## 17.53
rpd<-sqrt( var(dat.obs$macoma))/sqrt(mse.pimu)
rpd
@

\section{Effect of grid spacing}
\subsection{Select one simulated field}

<<criteria, eval=F>>=
#select X on 100 m that best resembles sibes
#function to define criteria to select simulated field that resembles sibes
#criteria 1: fraction of zeros
f1<-function(x){table(x>1)[1]/length(x)}
#criteria 2: mean of non zero
f2<-function(x){mean(subset(x,x!=0))}
#criteria 3: var of non zero
f3<-function(x){var(subset(x,x!=0))}
#load scaled sibes data
dat<-read.csv(file="./input/datsc.csv")
r1<-apply(dat[2],2,f1)
#0.80
r2<-apply(dat[2],2,f2)
#4.13
r3<-apply(dat[2],2,f3)
#59.24
#load simulated signals on 100 m grid from paper1/R4/output/predB or predP
predB<-readRDS("./input/predB.rds")
predP<-readRDS("./input/predP.rds")
varB<-readRDS("./input/varB.rds")
varP<-readRDS("./input/varP.rds")
#transform kriging prediction 
pred.pi<-mapply(transf.predB, var1.pred=predB[,-c(1:2)], var1.var=varB[,-c(1:2)])
var.pi<-mapply(transf.varB, var1.pred=predB[,-c(1:2)], var1.var=varB[,-c(1:2)]) #dont use?
pred.mu<-mapply(transf.predP, var1.pred=predP[,-c(1:2)], var1.var=varP[,-c(1:2)]) 
var.mu<-mapply(transf.varP, var1.pred=predP[,-c(1:2)], var1.var=varP[,-c(1:2)]) #dont use?
#obtain 100 field with counts
pred.count<-myfun.count(pred.pi,pred.mu)
#apply criteria
r1X<-apply(pred.count,2,f1)
r2X<-apply(pred.count,2,f2)
r3X<-apply(pred.count,2,f3)
#divide abs difference by standard deviation
r1Xa<- abs(r1-r1X)/(sd(abs(r1-r1X)))
r2Xa<- abs(r2-r2X)/(sd(abs(r2-r2X)))
r3Xa<- abs(r3-r3X)/(sd(abs(r3-r3X)))
#find sum of absolute differences
#assign weights 0.5, 0.25, 0.25
#and select min
rX<-0.5*r1Xa+0.25*r2Xa+0.25*r3Xa
which.min(rX)
#38
@

\subsection{Select validation points through stratified sampling}

<<valxy, eval=F>>=
##prediction grid with covariates
sgrid<-readRDS("input/sgrid.small.rds")
##set aside 1000 points based on tidal basins
##load tidal basins
tidalbasins.shp<-readOGR("./input/tidalbasins", "tidalbasins")
##reproject tidal basin
tidalbasins.shp<-spTransform(tidalbasins.shp, RD)
tb<-over(sgrid,tidalbasins.shp)
sgriddf<-as.data.frame(sgrid)
sgriddf$tb<-tb$TB
##compute size (number of points) of strata
Ntb<-table(tb$TB)
N<-sum(Ntb)
##compute sample sizes (proportional allocation)
n<-1000
#ntb<-round(Ntb/N*n)
sum(ntb)
##in stratum 1 only 1 point, change this to 2.
ids<-which(ntb<2)
ntb[ids]<-2
sumn<-sum(ntb)
ids<-which(ntb==max(ntb))
ntb[ids]<-ntb[ids]-(sum(ntb)-n)
sum(ntb)
stratumid<-sort(unique(tb$TB))
val<-NULL
##set aside 1000 points using tidal basins as strata
for (i in stratumid){
sam<-sgriddf[myfun.sample(which(sgriddf$tb==i),ntb[[as.character(i)]], replace=FALSE),] 
val<-rbind(val, sam)
}
##val.id
sgriddf$val.id<-row.names(sgriddf)%in%row.names(val)
#saveRDS(sgriddf, "output/sgriddf.rds")
sgriddf<-readRDS("output/sgriddf.rds")
val.xy<-subset(sgriddf, val.id==T, select=c(x1,x2))
#use avg of 100 realistaion instead of S38
predBdf<-data.frame(S=rowMeans(predB[,-c(1:2)]),sgriddf)
#add covariates
predBdf<-data.frame(S=predB$S38,sgriddf)
varBdf<-data.frame(S=varB$S38,sgriddf)
predPdf<-data.frame(S=predP$S38,sgriddf)
varPdf<-data.frame(S=varP$S38,sgriddf)
##prediction dataset
grdB<-predBdf[which(predBdf$val.id==F),]
grdB.var<-varBdf[which(varBdf$val.id==F),]
grdP<-predPdf[which(predPdf$val.id==F),]
grdP.var<-varPdf[which(varPdf$val.id==F),]
#validation dataset
valB<-predBdf[which(predBdf$val.id==T),]
valB.var<-varBdf[which(varBdf$val.id==T),]
valP<-predPdf[which(predPdf$val.id==T),]
valP.var<-varPdf[which(varPdf$val.id==T),]
#assign coordinates
coordinates(valB)<-~x1+x2
proj4string(valB)<-RD
coordinates(valP)<-~x1+x2
proj4string(valP)<-RD
coordinates(grdB)<-~x1+x2
proj4string(grdB)<-RD
coordinates(grdP)<-~x1+x2
proj4string(grdP)<-RD
gridded(grdB)<-TRUE
gridded(grdP)<-TRUE
saveRDS(grdB, file="output/grdB.rds")
saveRDS(grdB.var, file="output/grdB.var.rds")
saveRDS(grdP, file="output/grdP.rds")
saveRDS(grdP.var, file="output/grdP.var.rds")
saveRDS(valB, file="output/valB.rds")
saveRDS(valB.var, file="output/valB.var.rds")
saveRDS(valP, file="output/valP.rds")
saveRDS(valP.var, file="output/valP.var.rds")
@

<<fig-val.xy,fig.cap='1000 validation points allocated through stratified sampling using tidal basins as strata', out.width='0.8\\linewidth'>>=
val.xy<-readRDS("output/val.xy.rds")
gg.intertidal +
geom_point(data=val.xy,mapping = aes(x = x1/1000, y = x2/1000), size=0.8, colour="red", shape=3)
@

\subsection{Prediction with fixed model parameters}
\subsubsection{Model setup}

<<model, eval=F>>=
#MCML parameters evaluated on 100m grid
mcmlEstimation2B<-readRDS("input/bin.mcml2.rds")
mcmlEstimation2P<-readRDS("input/pois.mcml3.rds")
# define trend and model
trendB<-trendP<- S ~ silt + silt2 + depth
vgmB <- vgm(model="Sph",
  psill = mcmlEstimation2B$cov.pars[1],
  range= mcmlEstimation2B$cov.pars[2],
  nugget= mcmlEstimation2B$nugget.rel*mcmlEstimation2B$cov.pars[1])
vgmP <- vgm(model="Sph",
  psill = mcmlEstimation2P$cov.pars[1],
  range= mcmlEstimation2P$cov.pars[2],
  nugget= mcmlEstimation2P$nugget.rel*mcmlEstimation2P$cov.pars[1])
@

\subsubsection{Prediction Bernoulli}

<<eval=F, tidy=F>>=
set.seed(22800)
#grid spacing
spacing<-2^seq(1,7,1)*100 
# steekrproef number
nsteek<-100
seB<-seP<-se.pi<-se.mu<-prB<-prP<-array(dim=c(length(spacing), nsteek, 1000))
pr.pi<-pr.mu<-var.pi<-var.mu<-array(dim=c(length(spacing), nsteek, 1000))
npointsB<-npointsP<-array(dim=c(length(spacing),nsteek))
#binomial
for(k in 1:length(spacing)){
for (j in 1:nsteek){
s<- spsample(grdB, cellsize=spacing[k],type="regular")
npt<-length(s)
o<-over(s, grdB)
sam<-data.frame(s,o)
names(sam)[1:2]<-c("x1","x2")
sam<-na.omit(sam)
coordinates(sam)<-~x1+x2
proj4string(sam)<-RD
dataB<-sam
tmpB <- krige(
  formula = trendB,
  locations = dataB,
  newdata=valB,
  model = vgmB,
  beta = mcmlEstimation2B$beta,
  nmax=100,
  debug.level=1
)
#signal
prB[k,j,]<-tmpB@data$var1.pred
seB[k,j,]<-(tmpB@data$var1.pred-valB$S)^2
#pi
pr.pi[k,j,]<-transf.predB(tmpB@data$var1.pred,tmpB@data$var1.var)
#kriging variance
var.pi[k,j,]<-transf.varB(tmpB@data$var1.pred,tmpB@data$var1.var)
se.pi[k,j,]<-(transf.predB(tmpB@data$var1.pred, tmpB@data$var1.var)-
	      transf.predB(valB$S,valB.var$S))^2
npointsB[k,j]<-npt
}
}
@

\subsubsection{Predictions Poisson}
<<eval=F>>=
#poisson
for(k in 1:length(spacing)){
for (j in 1:nsteek){
s<- spsample(grdP, cellsize=spacing[k],type="regular")
npt<-length(s)
o<-over(s, grdP)
sam<-data.frame(s,o)
names(sam)[1:2]<-c("x1","x2")
sam<-na.omit(sam)
coordinates(sam)<-~x1+x2
proj4string(sam)<-RD
dataP<-sam
tmpP <- krige(
  formula = trendP,
  locations = dataP,
  newdata=valP,
  model = vgmP,
  beta = mcmlEstimation2P$beta,
  nmax=100,
  debug.level=1
)
#signal
prP[k,j,]<-tmpP@data$var1.pred
seP[k,j,]<-(tmpP@data$var1.pred-valP$S)^2
#mu
pr.mu[k,j,]<-transf.predP(tmpP@data$var1.pred,tmpP@data$var1.var)
#kriging variance
var.mu[k,j,]<-transf.varP(tmpP@data$var1.pred,tmpP@data$var1.var)
se.mu[k,j,]<-(transf.predP(tmpP@data$var1.pred, tmpP@data$var1.var)-transf.predP(valP$S,valP.var$S))^2
npointsP[k,j]<-npt
}
}
@

\subsubsection{Quality measures}

<<eval=F>>=
#calculate mse for signals B/P and for pi/mu
mseB<-apply(seB,c(1:2),mean)
mse.pi<-apply(se.pi,c(1:2),mean)
mseP<-apply(seP,c(1:2),mean)
mse.mu<-apply(se.mu,c(1:2),mean)
#1000 val points averaged over nsteek per grid spacing
mean.pr.pi<-apply(pr.pi,c(1,3),mean)
mean.pr.mu<-apply(pr.mu,c(1,3),mean)
val.pi<- transf.predB(valB$S,valB.var$S)
save(seB,seP,prB,prP, pr.pi, pr.mu,se.pi,se.mu,var.pi,var.mu, mse.pi, mse.mu, npointsB, npointsP,val.xy,val.pi, file="./output/results-mcml.RData")
@

<<results='asis'>>=
#measure of quality for pi
load(file="./output/results-mcml.RData")
bin.pr<-ifelse(apply(pr.pi, c(1,3), mean)>0.5,1,0)
valpi<-ifelse(val.pi>0.5,1,0)
spacing<-2^seq(2,7,1)*100 
conttb<-vector(mode="list", length=length(spacing))
for (i in 1:length(spacing)){
x00<-table(valpi, bin.pr[i,])[[1]]
x01<-table(valpi, bin.pr[i,])[[3]]
x10<-table(valpi, bin.pr[i,])[[2]]
x11<-table(valpi, bin.pr[i,])[[4]]
conttb[[i]]<-list(overall=(x11+x00)/(x00+x01+x10+x11),
users1= x11/(x11+x01),
users0= x00/(x00+x10),
prod1= x11/(x10+x11),
prod0= x00/(x00+x01)
)
}
df<-matrix(unlist(conttb), nrow=5, ncol=6)
colnames(df)<-spacing[1:6]
row.names(df)<-c("overall", "user1", "users0", "producers1", "producers0")
stargazer(df, title='Estimates of overall accuracy, users accuracy and producers accuracy for predicted prevalence calculated for different grid spacings (m) with fixed model parameters.  Average of 100 realisations.')
@

\subsection{Prediction with variable model parameters}
\subsubsection{Model setup}

<<eval=F>>=
#MCML parameters evaluated on 100m grid
mcmlEstimation2B<-readRDS("../R1/input/bin.mcml2.rds")
mcmlEstimation2P<-readRDS("../R1/input/pois.mcml3.rds")
@
\subsubsection{Prediction Bernoulli and Poisson}
<<eval=F, tidy=F>>=
#grid spacing
#start with 400m
spacing<-2^seq(2,7,1)*100 
k<-1
seB<-seP<-se.pi<-se.mu<-prB<-prP<-array(dim=c(length(spacing), 1000))
    pr.pi<-pr.mu<-var.pi<-var.mu<-array(dim=c(length(spacing), 1000))
remlB.conv<-remlP.conv<-remlB.sigmasq<-array(dim=c(length(spacing)))
remlP.sigmasq<-remlB.nugget<-remlP.nugget<- array(dim=c(length(spacing)))
remlB.phi<-remlP.phi<-npointsB<-npointsP<-array(dim=c(length(spacing)))
remlB.beta<-remlP.beta<-array(dim=c(length(spacing),(length(trendB)+1))) 
for(k in 1:length(spacing)){
#binomial
s<- spsample(grdB, cellsize=spacing[k],type="regular")
nptB<-length(s)
o<-over(s, grdB)
sam<-data.frame(s,o)
names(sam)[1:2]<-c("x1","x2")
sam<-na.omit(sam)
coordinates(sam)<-~x1+x2
proj4string(sam)<-RD
dataB<-sam
#poisson
s<- spsample(grdP, cellsize=spacing[k],type="regular")
nptP<-length(s)
o<-over(s, grdP)
sam<-data.frame(s,o)
names(sam)[1:2]<-c("x1","x2")
sam<-na.omit(sam)
coordinates(sam)<-~x1+x2
proj4string(sam)<-RD
dataP<-sam
trendB<-trendP<- ~ silt + silt2 + depth
#estimate parameters with reml
remlB <- likfit(
    geodata = as.geodata(sam,data.col="S",covar.col=c("silt", "silt2", "depth")),
    trend=trend.spatial(trend=trendB), 
    cov.model="spherical", 
    ini.cov.pars=c(mcmlEstimation2B$cov.pars[1], mcmlEstimation2B$cov.pars[2]), 
    nugget=mcmlEstimation2B$nugget.rel*mcmlEstimation2B$cov.pars[1],
    lik.method="REML"
)
remlP <- likfit(
    geodata = as.geodata(sam,data.col="S",covar.col=c("silt", "silt2", "depth")),
    trend=trend.spatial(trend=trendP), 
    cov.model="spherical", 
    ini.cov.pars=c(mcmlEstimation2P$cov.pars[1], mcmlEstimation2P$cov.pars[2]), 
    nugget=mcmlEstimation2P$nugget.rel*mcmlEstimation2P$cov.pars[1],
    lik.method="REML"
)
#check convergence
if(remlB$info.minimisation.function$convergence==0&
   remlP$info.minimisation.function$convergence==0){
if(remlB$phi==0) remlB$phi<-0.001
if(remlP$phi==0) remlP$phi<-0.001
#redefine trend
trendB<-trendP<- S ~ silt + silt2 + depth
#kriging S Bernoulli
tmpB <- krige(
  formula = trendB,
  locations = dataB,
  newdata=valB,
  model = vgm(model="Sph",psill=remlB$sigmasq,range=remlB$phi,nugget=remlB$nugget),
  beta = remlP$beta,
  nmax=100,
  debug.level=1
)
#signal
prB[k,]<-tmpB@data$var1.pred
seB[k,]<-(tmpB@data$var1.pred-valB$S)^2
#pi
pr.pi[k,]<-transf.predB(tmpB@data$var1.pred,tmpB@data$var1.var)
#kriging variance
var.pi[k,]<-transf.varB(tmpB@data$var1.pred,tmpB@data$var1.var)
se.pi[k,]<-(transf.predB(tmpB@data$var1.pred, tmpB@data$var1.var)-
	    transf.predB(valB$S,valB.var$S))^2
npointsB[k]<-nptB
#kriging S Poisson
tmpP <- krige(
  formula = trendP,
  locations = dataP,
  newdata=valP,
  model = vgm(model="Sph",psill=remlP$sigmasq,range=remlP$phi,nugget=remlP$nugget),
  beta = remlP$beta,
  nmax=100,
  debug.level=1
)
#signal
prP[k,]<-tmpP@data$var1.pred
seP[k,]<-(tmpP@data$var1.pred-valP$S)^2
#pi
pr.mu[k,]<-transf.predP(tmpP@data$var1.pred,tmpP@data$var1.var)
#kriging variance
var.mu[k,]<-transf.varP(tmpP@data$var1.pred,tmpP@data$var1.var)
se.mu[k,]<-(transf.predP(tmpP@data$var1.pred, tmpP@data$var1.var)-
	    transf.predP(valP$S,valP.var$S))^2
npointsP[k]<-nptP
#accumulate reml convergence
remlB.conv[k]<-remlB$info.minimisation.function$convergence
remlB.phi[k]<-remlB$phi
remlB.sigmasq[k]<-remlB$sigmasq
remlB.nugget[k]<-remlB$nugget
remlP.conv[k]<-remlP$info.minimisation.function$convergence
remlP.phi[k]<-remlP$phi
remlP.sigmasq[k]<-remlP$sigmasq
remlP.nugget[k]<-remlP$nugget
remlB.beta[k,]<-remlB$beta
remlP.beta[k,]<-remlP$beta
}
}
@

\subsubsection{Quality measures}
<<eval=F>>=
mse.pi<-apply(se.pi,1,mean)
mse.mu<-apply(se.mu,1,mean)
mse.pi
mse.mu
val.pi<-transf.predB(valB$S,valB.var$S)
val.mu<-transf.predP(valP$S,valP.var$S)
#add results400
#save all results 
save(mse.pi, mse.mu, seB,seP,prB,prP, pr.pi, pr.mu,se.pi,se.mu,var.pi,var.mu, npointsB, npointsP,val.xy, val.pi, val.mu,
     file="./output/results-reml1.RData")
#save reml parameters
save(remlB.conv, remlP.conv, remlB.sigmasq, remlP.sigmasq, remlB.nugget, remlP.nugget, npointsB, npointsP, remlB.beta, remlP.beta,
     file="./output/reml1.RData")
@

<<accuracy-reml,results='asis'>>=
load(file="./output/results-reml1.RData")
pr.pi.reml1<-pr.pi
my.list<-list(pr.pi.reml1)
df<- Reduce("+", my.list) / length(my.list)
bin.pr<-ifelse(df>0.5,1,0)
valpi<-ifelse(val.pi>0.5,1,0)
conttb<-vector(mode="list", length=length(spacing[-1]))
for (i in 1:length(spacing[-1])){
x00<-table(valpi, bin.pr[i,])[[1]]
x01<-table(valpi, bin.pr[i,])[[3]]
x10<-table(valpi, bin.pr[i,])[[2]]
x11<-table(valpi, bin.pr[i,])[[4]]
conttb[[i]]<-list(overall=(x11+x00)/(x00+x01+x10+x11),
users1= x11/(x11+x01),
users0= x00/(x00+x10),
prod1= x11/(x10+x11),
prod0= x00/(x00+x01)
)
}
df<-matrix(unlist(conttb), nrow=5, ncol=6)
colnames(df)<-spacing[1:6]
row.names(df)<-c("overall", "user1", "users0", "producers1", "producers0")
stargazer(df, title='Estimates of overall accuracy, users accuracy and producers accuracy for predicted prevalence calculated for different grid spacings (m) with variable model parameters')
@

<<out.width='.49\\linewidth', fig.cap="Unconditional intensity predicted at 1000 validation points by simple kriging with an external drift with variable model parameters from 400 (a), 800 (b), 1600 (c), 3200 (d), 6400 (e), 12800 (f) m grid.">>=

load(file="./output/results-reml1.RData")
pr.pi.reml1<-pr.pi
pr.mu.reml1<-pr.mu
spacing<-2^seq(1,7,1)*100 
#combine pi mu and take avg
my.list<-list(pr.pi.reml1*pr.mu.reml1)
df<- Reduce("+", my.list) / length(my.list)
row.names(df)<-spacing[-1]
#use the same splits as for 100 m for comparison
b<-c(-Inf,0.3,0.7,1.5, Inf)
l<-c("[0-0.3)", "[0.3-0.7)","[0.7-1.5)", "[1.5-Inf)")
colo<-c("#FFFF00", "#AAD800", "#55B100", "#008B00")
tmp<-cbind(val.xy, t(df))
tmp<-melt(tmp, id=c("x1","x2"))
tmp$group<-cut(tmp$value, breaks=b, labels=l, right=F) 
for (i in spacing[-1]){
print(gg.intertidal+ geom_point(data = subset(tmp, variable==i), aes( x = x1* 1.0e-3, y = x2* 1.0e-3, colour=group),size=0.7)+
scale_colour_manual(name="", values = colo)+
coord_equal(ratio = 1)+
theme(legend.position="bottom", panel.background = element_rect(fill="white", color=NA), 
     panel.border = element_rect(colour = "grey50", fill=NA))+ 
guides(colour = guide_legend(override.aes = list(size=3)))
)
}
@

<<out.width='.49\\linewidth', fig.cap="The MSE for predicted intensity (a) and predicted unconditional intensity (b) as a function of grid spacing for 200, 400, 800, 1600, 3200, 6400, and 12800 m.  Predictions were obtained by simple kriging with an external drift with fixed model parameters (blue) and variable model parameters (red).", tidy=F>>=
load(file="output/results-reml1.RData")
mse.mu.reml1<-apply(se.mu,1,mean)
mse.pi.reml1<-apply(se.pi,1,mean)
load(file="./output/results-mcml.RData")
mse.mu.mcml<-mse.mu
mse.pi.mcml<-mse.pi
spacing<-2^seq(1,7,1)*100 
row.names(mse.mu.mcml)<-spacing
df1<-melt(mse.mu.mcml)
df2<-data.frame(spacing, mse.mu.reml=c(NA, mse.mu.reml1))
ggplot(df1, aes(x=as.factor(Var1), y=value))+
geom_boxplot(outlier.size=2, notch=F, fill="skyblue")+
geom_point(data=df2,
	   aes(x=as.factor(spacing), y=mse.mu.reml), 
	   size=3, 
	   shape=8, 
	   col="red")+
scale_x_discrete(name = "Spacing (m)") + 
scale_y_continuous(name = "MSE (intensity)")+
theme_bw()
row.names(mse.pi.mcml)<-spacing
df1<-melt(mse.pi.mcml*mse.mu.mcml)
df2<-data.frame(spacing, mse.pimu.reml=c(NA, mse.pi.reml1*mse.mu.reml1)) 
ggplot(df1, aes(x=as.factor(Var1), y=value))+
geom_boxplot(outlier.size=2, notch=F, fill="skyblue")+
geom_point(data=df2, aes(x=as.factor(spacing), y=mse.pimu.reml), 
	   size=3, 
	   shape=8, 
	   col="red")+
scale_x_discrete(name = "Spacing (m)") + 
scale_y_continuous(limits=c(0,0.1), 
		   name = "MSE (unconditional intensity)")+
theme_bw()
@

\end{document}
